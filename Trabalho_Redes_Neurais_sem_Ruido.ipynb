{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Trabalho_Redes_Neurais_sem_Ruido.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfyIirJMmQEB"
      },
      "source": [
        "# Rede Neural para Acidentes em uma Usina Nuclear - Sem ruído"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P6NImUAmQEC"
      },
      "source": [
        "## Bibliotecas usadas na implementação da rede"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg_krSP4mQEC"
      },
      "source": [
        "import numpy as np # será usada para mexer com vetores e matrizes\n",
        "import pandas as pd # será usada para mexer com o arquivo Excel\n",
        "import matplotlib.pyplot as plt # será usada para mostrar os gráficos desejados\n",
        "from sklearn.preprocessing import MinMaxScaler # será usada para normalizar os dados do Excel\n",
        "from sklearn.model_selection import train_test_split # será usada para dividir o conjunto de dados do arquivo Excel\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score # será usada para analisar o            \n",
        "                                                                                                        # funcionamento da rede\n",
        "from tensorflow import random \n",
        "from tensorflow.keras import layers, models, optimizers # será usada na construção da rede\n",
        "\n",
        "############Setando Semente Randomica\n",
        "seed = 1\n",
        "np.random.seed(seed)\n",
        "random.set_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_imqEEHmQEG"
      },
      "source": [
        "## Abrindo o arquivo Excel para leitura"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCBJvBIBmQEG"
      },
      "source": [
        "dados = pd.read_excel(\"/content/sample_data/16_operational_scenarios.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOGjITvWmQEI"
      },
      "source": [
        "## Selecionando os dados de entrada/saída"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkrvyd94mQEJ"
      },
      "source": [
        "entradas = dados.iloc[:,0:17]\n",
        "saidas = dados.iloc[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I69WkrYOmQEM"
      },
      "source": [
        "## Selecionando os dados que serão usados para treinamento, teste e validação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJncwbWrmQEM"
      },
      "source": [
        "entradasTreino, entradasTeste, saidasTreino, saidasTeste = train_test_split(entradas, saidas, test_size=0.05)\n",
        "entradasTreino, entradasValid, saidasTreino, saidasValid = train_test_split(entradasTreino, saidasTreino, test_size=0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EHGP50VmQES"
      },
      "source": [
        "## Normalizando os dados de entrada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0DxTUtdmQEW"
      },
      "source": [
        "normalizer = MinMaxScaler(feature_range = (0, 1))\n",
        "entradasTreino = normalizer.fit_transform(entradasTreino)\n",
        "entradasValid = normalizer.transform(entradasValid)\n",
        "entradasTeste = normalizer.transform(entradasTeste)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlZj-Q2fmQEZ"
      },
      "source": [
        "## Definindo as quantidas de entradas, saídas, neurônios funções de ativação, tipo de otimizador, função erro, tamanho do batch e o número de épocas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR2icT55mQEZ"
      },
      "source": [
        "quant_entradas = entradasTreino.shape[1]\n",
        "quant_saidas = 1\n",
        "quant_neuronios = 40\n",
        "funcaoAtivacao = \"relu\"\n",
        "funcaoSaida = \"linear\"\n",
        "optimizer = optimizers.Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=1E-8, decay=0.0)\n",
        "funcaoErro ='mse'\n",
        "batch_size = 50\n",
        "epochs =  400"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyR1nbC9mQEb"
      },
      "source": [
        "## Estrutrando a rede"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBWcXZMOmQEc",
        "outputId": "5ed2dd0d-e094-4bc6-d2e5-cab162a81e16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Dense(quant_neuronios,\n",
        "                        activation=funcaoAtivacao, \n",
        "                        input_dim=quant_entradas))\n",
        "\n",
        "#Camada Escondida 2\n",
        "model.add(layers.Dense(quant_neuronios,activation=funcaoAtivacao))\n",
        "model.add(layers.Dense(quant_neuronios,activation=funcaoAtivacao))\n",
        "model.add(layers.Dense(quant_neuronios,activation=funcaoAtivacao))\n",
        "model.add(layers.Dense(quant_neuronios,activation=funcaoAtivacao))\n",
        "model.add(layers.Dense(quant_neuronios,activation=funcaoAtivacao))\n",
        "\n",
        "#Camada de Saida\n",
        "model.add(layers.Dense(quant_saidas,activation=funcaoSaida))\n",
        "\n",
        "#Resumo do Modelo\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_49 (Dense)             (None, 40)                720       \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 40)                1640      \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 40)                1640      \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 40)                1640      \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 40)                1640      \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 40)                1640      \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 1)                 41        \n",
            "=================================================================\n",
            "Total params: 8,961\n",
            "Trainable params: 8,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1x1MDqzmQEe"
      },
      "source": [
        "## Compilando a rede neural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHg4nKQNmQEe"
      },
      "source": [
        "model.compile(loss=funcaoErro, optimizer=optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2hI9Om1mQEl"
      },
      "source": [
        "## Treinando a rede neural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_Z2tHH3mQEl",
        "outputId": "59cdc6b8-1b74-4b94-8e51-248c7054b99d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit(entradasTreino, saidasTreino, \n",
        "          epochs=epochs, batch_size=batch_size, \n",
        "          validation_data=(entradasValid, saidasValid),\n",
        "          shuffle=True,\n",
        "          verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 26.5566 - val_loss: 10.4398\n",
            "Epoch 2/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 9.4257 - val_loss: 9.1704\n",
            "Epoch 3/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5.3513 - val_loss: 2.2042\n",
            "Epoch 4/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 4.8062 - val_loss: 1.5196\n",
            "Epoch 5/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.8359 - val_loss: 4.7662\n",
            "Epoch 6/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3.1148 - val_loss: 1.5819\n",
            "Epoch 7/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.8647 - val_loss: 1.9929\n",
            "Epoch 8/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.8286 - val_loss: 3.3634\n",
            "Epoch 9/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.6224 - val_loss: 1.6447\n",
            "Epoch 10/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.6062 - val_loss: 3.0664\n",
            "Epoch 11/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.4745 - val_loss: 2.5840\n",
            "Epoch 12/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.4130 - val_loss: 2.2471\n",
            "Epoch 13/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 2.4984 - val_loss: 2.3825\n",
            "Epoch 14/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.3517 - val_loss: 3.1879\n",
            "Epoch 15/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.3357 - val_loss: 2.0806\n",
            "Epoch 16/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.5701 - val_loss: 2.8203\n",
            "Epoch 17/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.3812 - val_loss: 3.0257\n",
            "Epoch 18/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.3263 - val_loss: 2.3515\n",
            "Epoch 19/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.2704 - val_loss: 3.3606\n",
            "Epoch 20/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.3578 - val_loss: 2.5663\n",
            "Epoch 21/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1773 - val_loss: 3.7292\n",
            "Epoch 22/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.3301 - val_loss: 2.4434\n",
            "Epoch 23/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.2212 - val_loss: 2.5604\n",
            "Epoch 24/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.1391 - val_loss: 2.0348\n",
            "Epoch 25/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.2655 - val_loss: 3.1957\n",
            "Epoch 26/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1688 - val_loss: 2.1480\n",
            "Epoch 27/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.1071 - val_loss: 2.3279\n",
            "Epoch 28/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.1030 - val_loss: 2.4094\n",
            "Epoch 29/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.1178 - val_loss: 3.1024\n",
            "Epoch 30/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.2983 - val_loss: 1.3515\n",
            "Epoch 31/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.5296 - val_loss: 3.9512\n",
            "Epoch 32/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.3614 - val_loss: 2.0009\n",
            "Epoch 33/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0784 - val_loss: 3.8421\n",
            "Epoch 34/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0671 - val_loss: 1.9331\n",
            "Epoch 35/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0005 - val_loss: 3.1272\n",
            "Epoch 36/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9193 - val_loss: 1.7920\n",
            "Epoch 37/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.1704 - val_loss: 4.2231\n",
            "Epoch 38/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0142 - val_loss: 1.9982\n",
            "Epoch 39/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.0891 - val_loss: 2.3752\n",
            "Epoch 40/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9308 - val_loss: 2.4080\n",
            "Epoch 41/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.8671 - val_loss: 3.0579\n",
            "Epoch 42/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.8626 - val_loss: 1.7791\n",
            "Epoch 43/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.9275 - val_loss: 2.0851\n",
            "Epoch 44/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8521 - val_loss: 2.4490\n",
            "Epoch 45/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0021 - val_loss: 3.1598\n",
            "Epoch 46/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7994 - val_loss: 1.5542\n",
            "Epoch 47/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9178 - val_loss: 4.3044\n",
            "Epoch 48/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8965 - val_loss: 1.2693\n",
            "Epoch 49/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8981 - val_loss: 2.2197\n",
            "Epoch 50/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7086 - val_loss: 2.4674\n",
            "Epoch 51/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7140 - val_loss: 2.5367\n",
            "Epoch 52/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7571 - val_loss: 2.3546\n",
            "Epoch 53/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7309 - val_loss: 1.1395\n",
            "Epoch 54/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0605 - val_loss: 1.6524\n",
            "Epoch 55/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.4055 - val_loss: 6.1634\n",
            "Epoch 56/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.2848 - val_loss: 1.2570\n",
            "Epoch 57/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7789 - val_loss: 4.4516\n",
            "Epoch 58/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.9085 - val_loss: 1.6674\n",
            "Epoch 59/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7673 - val_loss: 2.0496\n",
            "Epoch 60/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7370 - val_loss: 2.0236\n",
            "Epoch 61/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6339 - val_loss: 2.4031\n",
            "Epoch 62/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.6366 - val_loss: 1.3878\n",
            "Epoch 63/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6695 - val_loss: 2.2691\n",
            "Epoch 64/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.6008 - val_loss: 1.4167\n",
            "Epoch 65/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6315 - val_loss: 2.1093\n",
            "Epoch 66/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5655 - val_loss: 3.4545\n",
            "Epoch 67/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1435 - val_loss: 1.0141\n",
            "Epoch 68/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7631 - val_loss: 5.9362\n",
            "Epoch 69/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0140 - val_loss: 1.4617\n",
            "Epoch 70/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8854 - val_loss: 3.0775\n",
            "Epoch 71/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8461 - val_loss: 1.7598\n",
            "Epoch 72/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0529 - val_loss: 1.0203\n",
            "Epoch 73/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.1487 - val_loss: 5.2165\n",
            "Epoch 74/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.2798 - val_loss: 1.9389\n",
            "Epoch 75/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9011 - val_loss: 2.7473\n",
            "Epoch 76/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.6635 - val_loss: 1.3391\n",
            "Epoch 77/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6840 - val_loss: 2.1520\n",
            "Epoch 78/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7133 - val_loss: 1.6666\n",
            "Epoch 79/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.5622 - val_loss: 1.4290\n",
            "Epoch 80/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6517 - val_loss: 2.7560\n",
            "Epoch 81/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5899 - val_loss: 1.0541\n",
            "Epoch 82/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7423 - val_loss: 0.7884\n",
            "Epoch 83/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7411 - val_loss: 2.4340\n",
            "Epoch 84/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5314 - val_loss: 1.9380\n",
            "Epoch 85/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5031 - val_loss: 0.7974\n",
            "Epoch 86/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5437 - val_loss: 2.3080\n",
            "Epoch 87/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4118 - val_loss: 0.9955\n",
            "Epoch 88/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6157 - val_loss: 0.8812\n",
            "Epoch 89/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.5546 - val_loss: 1.5942\n",
            "Epoch 90/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3248 - val_loss: 0.8819\n",
            "Epoch 91/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3329 - val_loss: 0.9892\n",
            "Epoch 92/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2875 - val_loss: 0.9568\n",
            "Epoch 93/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3509 - val_loss: 2.8822\n",
            "Epoch 94/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4153 - val_loss: 0.6540\n",
            "Epoch 95/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2578 - val_loss: 0.7018\n",
            "Epoch 96/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4914 - val_loss: 1.5648\n",
            "Epoch 97/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5735 - val_loss: 3.5210\n",
            "Epoch 98/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8959 - val_loss: 0.8744\n",
            "Epoch 99/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7178 - val_loss: 1.3855\n",
            "Epoch 100/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 2.0201 - val_loss: 6.1946\n",
            "Epoch 101/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.9630 - val_loss: 1.6308\n",
            "Epoch 102/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.7084 - val_loss: 2.6959\n",
            "Epoch 103/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.6159 - val_loss: 1.2727\n",
            "Epoch 104/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5431 - val_loss: 2.3595\n",
            "Epoch 105/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5449 - val_loss: 2.0309\n",
            "Epoch 106/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3764 - val_loss: 0.9067\n",
            "Epoch 107/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3846 - val_loss: 0.8496\n",
            "Epoch 108/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4253 - val_loss: 0.8009\n",
            "Epoch 109/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4041 - val_loss: 0.9757\n",
            "Epoch 110/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2472 - val_loss: 0.6681\n",
            "Epoch 111/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1914 - val_loss: 1.1254\n",
            "Epoch 112/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1829 - val_loss: 0.4719\n",
            "Epoch 113/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.5452 - val_loss: 0.6141\n",
            "Epoch 114/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4416 - val_loss: 1.9877\n",
            "Epoch 115/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3610 - val_loss: 2.0392\n",
            "Epoch 116/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4958 - val_loss: 0.6763\n",
            "Epoch 117/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4191 - val_loss: 1.2976\n",
            "Epoch 118/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5489 - val_loss: 0.8478\n",
            "Epoch 119/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6927 - val_loss: 0.6636\n",
            "Epoch 120/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.9723 - val_loss: 5.9640\n",
            "Epoch 121/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8672 - val_loss: 1.1925\n",
            "Epoch 122/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.8990 - val_loss: 2.8456\n",
            "Epoch 123/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.8787 - val_loss: 1.9690\n",
            "Epoch 124/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.6093 - val_loss: 1.9240\n",
            "Epoch 125/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6136 - val_loss: 1.2730\n",
            "Epoch 126/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4681 - val_loss: 1.6410\n",
            "Epoch 127/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3720 - val_loss: 1.7004\n",
            "Epoch 128/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3234 - val_loss: 1.2743\n",
            "Epoch 129/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1884 - val_loss: 0.8168\n",
            "Epoch 130/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0622 - val_loss: 0.4382\n",
            "Epoch 131/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0215 - val_loss: 0.8630\n",
            "Epoch 132/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0284 - val_loss: 1.5994\n",
            "Epoch 133/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.2326 - val_loss: 0.3640\n",
            "Epoch 134/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0671 - val_loss: 0.3184\n",
            "Epoch 135/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1303 - val_loss: 0.3846\n",
            "Epoch 136/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4134 - val_loss: 1.3018\n",
            "Epoch 137/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0573 - val_loss: 0.7920\n",
            "Epoch 138/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1323 - val_loss: 0.2804\n",
            "Epoch 139/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1945 - val_loss: 1.7368\n",
            "Epoch 140/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1817 - val_loss: 0.7601\n",
            "Epoch 141/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1917 - val_loss: 0.4368\n",
            "Epoch 142/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.2841 - val_loss: 1.3096\n",
            "Epoch 143/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9374 - val_loss: 0.5315\n",
            "Epoch 144/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1461 - val_loss: 1.3182\n",
            "Epoch 145/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0618 - val_loss: 0.2716\n",
            "Epoch 146/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9399 - val_loss: 0.3189\n",
            "Epoch 147/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8571 - val_loss: 0.3706\n",
            "Epoch 148/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0373 - val_loss: 0.4287\n",
            "Epoch 149/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.2041 - val_loss: 1.7387\n",
            "Epoch 150/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9661 - val_loss: 0.2343\n",
            "Epoch 151/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9321 - val_loss: 0.9341\n",
            "Epoch 152/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9044 - val_loss: 0.3305\n",
            "Epoch 153/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0496 - val_loss: 0.3466\n",
            "Epoch 154/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.2014 - val_loss: 0.2092\n",
            "Epoch 155/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.8915 - val_loss: 0.6349\n",
            "Epoch 156/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.8908 - val_loss: 0.4338\n",
            "Epoch 157/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8933 - val_loss: 0.8570\n",
            "Epoch 158/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8287 - val_loss: 0.4904\n",
            "Epoch 159/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8863 - val_loss: 1.4614\n",
            "Epoch 160/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8176 - val_loss: 0.2102\n",
            "Epoch 161/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7126 - val_loss: 0.2456\n",
            "Epoch 162/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7278 - val_loss: 0.1187\n",
            "Epoch 163/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9209 - val_loss: 0.3827\n",
            "Epoch 164/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9939 - val_loss: 0.2590\n",
            "Epoch 165/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7740 - val_loss: 0.2923\n",
            "Epoch 166/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6808 - val_loss: 0.1025\n",
            "Epoch 167/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7551 - val_loss: 0.1065\n",
            "Epoch 168/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8263 - val_loss: 0.4157\n",
            "Epoch 169/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8258 - val_loss: 1.2128\n",
            "Epoch 170/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.5254 - val_loss: 0.8916\n",
            "Epoch 171/400\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.9943 - val_loss: 0.8631\n",
            "Epoch 172/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.3869 - val_loss: 6.2691\n",
            "Epoch 173/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2.2152 - val_loss: 0.8472\n",
            "Epoch 174/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.7188 - val_loss: 1.7633\n",
            "Epoch 175/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.5632 - val_loss: 1.2988\n",
            "Epoch 176/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4685 - val_loss: 2.5083\n",
            "Epoch 177/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4153 - val_loss: 1.2128\n",
            "Epoch 178/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.3571 - val_loss: 1.4789\n",
            "Epoch 179/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.3242 - val_loss: 0.9541\n",
            "Epoch 180/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.1426 - val_loss: 0.5943\n",
            "Epoch 181/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.3191 - val_loss: 0.4329\n",
            "Epoch 182/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0932 - val_loss: 2.1793\n",
            "Epoch 183/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1486 - val_loss: 0.5116\n",
            "Epoch 184/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2683 - val_loss: 0.7681\n",
            "Epoch 185/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3158 - val_loss: 1.7724\n",
            "Epoch 186/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0860 - val_loss: 0.6721\n",
            "Epoch 187/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9800 - val_loss: 0.2666\n",
            "Epoch 188/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0375 - val_loss: 0.4145\n",
            "Epoch 189/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4463 - val_loss: 1.3025\n",
            "Epoch 190/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4811 - val_loss: 4.0446\n",
            "Epoch 191/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2279 - val_loss: 0.8091\n",
            "Epoch 192/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6085 - val_loss: 3.2166\n",
            "Epoch 193/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2023 - val_loss: 0.3081\n",
            "Epoch 194/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.2977 - val_loss: 0.5510\n",
            "Epoch 195/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4101 - val_loss: 1.6394\n",
            "Epoch 196/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1196 - val_loss: 0.8069\n",
            "Epoch 197/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9183 - val_loss: 0.3164\n",
            "Epoch 198/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8687 - val_loss: 0.2178\n",
            "Epoch 199/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8932 - val_loss: 0.5648\n",
            "Epoch 200/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8288 - val_loss: 0.6868\n",
            "Epoch 201/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7204 - val_loss: 0.2427\n",
            "Epoch 202/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7006 - val_loss: 0.1542\n",
            "Epoch 203/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9181 - val_loss: 0.2268\n",
            "Epoch 204/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9293 - val_loss: 0.1890\n",
            "Epoch 205/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.9502 - val_loss: 1.4695\n",
            "Epoch 206/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0958 - val_loss: 0.7803\n",
            "Epoch 207/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0114 - val_loss: 0.5591\n",
            "Epoch 208/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2962 - val_loss: 0.3000\n",
            "Epoch 209/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8955 - val_loss: 2.2456\n",
            "Epoch 210/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9851 - val_loss: 0.5845\n",
            "Epoch 211/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9660 - val_loss: 0.2579\n",
            "Epoch 212/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0589 - val_loss: 1.2978\n",
            "Epoch 213/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0583 - val_loss: 0.2303\n",
            "Epoch 214/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7957 - val_loss: 0.3006\n",
            "Epoch 215/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.8999 - val_loss: 0.3466\n",
            "Epoch 216/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9229 - val_loss: 1.4982\n",
            "Epoch 217/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8805 - val_loss: 0.5552\n",
            "Epoch 218/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8958 - val_loss: 0.9612\n",
            "Epoch 219/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7284 - val_loss: 0.2952\n",
            "Epoch 220/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8841 - val_loss: 0.6729\n",
            "Epoch 221/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7900 - val_loss: 0.3068\n",
            "Epoch 222/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6922 - val_loss: 0.3033\n",
            "Epoch 223/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5970 - val_loss: 0.3587\n",
            "Epoch 224/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5550 - val_loss: 0.1883\n",
            "Epoch 225/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6029 - val_loss: 0.2180\n",
            "Epoch 226/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5660 - val_loss: 0.1363\n",
            "Epoch 227/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6079 - val_loss: 0.6738\n",
            "Epoch 228/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8522 - val_loss: 0.5866\n",
            "Epoch 229/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7097 - val_loss: 0.2704\n",
            "Epoch 230/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6399 - val_loss: 0.2440\n",
            "Epoch 231/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6469 - val_loss: 0.2190\n",
            "Epoch 232/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5580 - val_loss: 0.6496\n",
            "Epoch 233/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7768 - val_loss: 0.1676\n",
            "Epoch 234/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6727 - val_loss: 0.1703\n",
            "Epoch 235/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5875 - val_loss: 0.1796\n",
            "Epoch 236/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5236 - val_loss: 0.2181\n",
            "Epoch 237/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8894 - val_loss: 0.1246\n",
            "Epoch 238/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6726 - val_loss: 0.1796\n",
            "Epoch 239/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6188 - val_loss: 0.1599\n",
            "Epoch 240/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6346 - val_loss: 0.6121\n",
            "Epoch 241/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8348 - val_loss: 0.1869\n",
            "Epoch 242/400\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6571 - val_loss: 0.1711\n",
            "Epoch 243/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5198 - val_loss: 0.2082\n",
            "Epoch 244/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5699 - val_loss: 0.1961\n",
            "Epoch 245/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5738 - val_loss: 0.3187\n",
            "Epoch 246/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5393 - val_loss: 0.2123\n",
            "Epoch 247/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6973 - val_loss: 0.5825\n",
            "Epoch 248/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5029 - val_loss: 0.2280\n",
            "Epoch 249/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4622 - val_loss: 0.1426\n",
            "Epoch 250/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4322 - val_loss: 0.1154\n",
            "Epoch 251/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4279 - val_loss: 0.3458\n",
            "Epoch 252/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4288 - val_loss: 0.1941\n",
            "Epoch 253/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5098 - val_loss: 0.2384\n",
            "Epoch 254/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4649 - val_loss: 0.1292\n",
            "Epoch 255/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4136 - val_loss: 0.1292\n",
            "Epoch 256/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4579 - val_loss: 0.1374\n",
            "Epoch 257/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7380 - val_loss: 0.1718\n",
            "Epoch 258/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7328 - val_loss: 0.2104\n",
            "Epoch 259/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5786 - val_loss: 0.4668\n",
            "Epoch 260/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5381 - val_loss: 0.1005\n",
            "Epoch 261/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5668 - val_loss: 0.2216\n",
            "Epoch 262/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4324 - val_loss: 0.2859\n",
            "Epoch 263/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5779 - val_loss: 0.2494\n",
            "Epoch 264/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6476 - val_loss: 0.2533\n",
            "Epoch 265/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5406 - val_loss: 0.1376\n",
            "Epoch 266/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0048 - val_loss: 0.4489\n",
            "Epoch 267/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0456 - val_loss: 2.1561\n",
            "Epoch 268/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1528 - val_loss: 0.6690\n",
            "Epoch 269/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0278 - val_loss: 0.8058\n",
            "Epoch 270/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.3551 - val_loss: 0.0628\n",
            "Epoch 271/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0404 - val_loss: 0.7131\n",
            "Epoch 272/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9306 - val_loss: 0.0963\n",
            "Epoch 273/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.8928 - val_loss: 0.3955\n",
            "Epoch 274/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0973 - val_loss: 0.8862\n",
            "Epoch 275/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9143 - val_loss: 0.2129\n",
            "Epoch 276/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9448 - val_loss: 0.1245\n",
            "Epoch 277/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6623 - val_loss: 0.0534\n",
            "Epoch 278/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4903 - val_loss: 0.1322\n",
            "Epoch 279/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5483 - val_loss: 0.2066\n",
            "Epoch 280/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4811 - val_loss: 0.1795\n",
            "Epoch 281/400\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4442 - val_loss: 0.1312\n",
            "Epoch 282/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4358 - val_loss: 0.1913\n",
            "Epoch 283/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4612 - val_loss: 0.0941\n",
            "Epoch 284/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4474 - val_loss: 0.1266\n",
            "Epoch 285/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4136 - val_loss: 0.0812\n",
            "Epoch 286/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4027 - val_loss: 0.1376\n",
            "Epoch 287/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5253 - val_loss: 0.1948\n",
            "Epoch 288/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5458 - val_loss: 0.1794\n",
            "Epoch 289/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4410 - val_loss: 0.0783\n",
            "Epoch 290/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5362 - val_loss: 0.3486\n",
            "Epoch 291/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6108 - val_loss: 0.0934\n",
            "Epoch 292/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4624 - val_loss: 0.1568\n",
            "Epoch 293/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3964 - val_loss: 0.1819\n",
            "Epoch 294/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3793 - val_loss: 0.1700\n",
            "Epoch 295/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4016 - val_loss: 0.1056\n",
            "Epoch 296/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4000 - val_loss: 0.1715\n",
            "Epoch 297/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4139 - val_loss: 0.0784\n",
            "Epoch 298/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5178 - val_loss: 0.0276\n",
            "Epoch 299/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4245 - val_loss: 0.1706\n",
            "Epoch 300/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4994 - val_loss: 0.4453\n",
            "Epoch 301/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6437 - val_loss: 0.2470\n",
            "Epoch 302/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7937 - val_loss: 0.0677\n",
            "Epoch 303/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4507 - val_loss: 3.3630\n",
            "Epoch 304/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0975 - val_loss: 0.3959\n",
            "Epoch 305/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2434 - val_loss: 0.3363\n",
            "Epoch 306/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9776 - val_loss: 0.4037\n",
            "Epoch 307/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8045 - val_loss: 0.1150\n",
            "Epoch 308/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4688 - val_loss: 0.0796\n",
            "Epoch 309/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5373 - val_loss: 0.3210\n",
            "Epoch 310/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8365 - val_loss: 1.5030\n",
            "Epoch 311/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9688 - val_loss: 0.3908\n",
            "Epoch 312/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6266 - val_loss: 0.1042\n",
            "Epoch 313/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6368 - val_loss: 0.0545\n",
            "Epoch 314/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4418 - val_loss: 0.3197\n",
            "Epoch 315/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5117 - val_loss: 0.1462\n",
            "Epoch 316/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5593 - val_loss: 0.1979\n",
            "Epoch 317/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4432 - val_loss: 0.1243\n",
            "Epoch 318/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5237 - val_loss: 0.5903\n",
            "Epoch 319/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6413 - val_loss: 0.0733\n",
            "Epoch 320/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4329 - val_loss: 0.1070\n",
            "Epoch 321/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3725 - val_loss: 0.1151\n",
            "Epoch 322/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3585 - val_loss: 0.1272\n",
            "Epoch 323/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3757 - val_loss: 0.1102\n",
            "Epoch 324/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4418 - val_loss: 0.0983\n",
            "Epoch 325/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4298 - val_loss: 1.3118\n",
            "Epoch 326/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7306 - val_loss: 0.1981\n",
            "Epoch 327/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5544 - val_loss: 0.1458\n",
            "Epoch 328/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3967 - val_loss: 0.1532\n",
            "Epoch 329/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3631 - val_loss: 0.5397\n",
            "Epoch 330/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4407 - val_loss: 0.1155\n",
            "Epoch 331/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4007 - val_loss: 0.1117\n",
            "Epoch 332/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3819 - val_loss: 0.1771\n",
            "Epoch 333/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3530 - val_loss: 0.1303\n",
            "Epoch 334/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4358 - val_loss: 0.1319\n",
            "Epoch 335/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3791 - val_loss: 0.0938\n",
            "Epoch 336/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4917 - val_loss: 0.0131\n",
            "Epoch 337/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5742 - val_loss: 0.1070\n",
            "Epoch 338/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4854 - val_loss: 0.7447\n",
            "Epoch 339/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6135 - val_loss: 0.1541\n",
            "Epoch 340/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1638 - val_loss: 0.3736\n",
            "Epoch 341/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9809 - val_loss: 2.9968\n",
            "Epoch 342/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.8150 - val_loss: 0.0559\n",
            "Epoch 343/400\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4481 - val_loss: 0.0997\n",
            "Epoch 344/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3832 - val_loss: 0.1064\n",
            "Epoch 345/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3565 - val_loss: 0.1673\n",
            "Epoch 346/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3726 - val_loss: 0.1814\n",
            "Epoch 347/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4230 - val_loss: 0.1505\n",
            "Epoch 348/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5535 - val_loss: 0.1618\n",
            "Epoch 349/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4665 - val_loss: 1.2308\n",
            "Epoch 350/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6357 - val_loss: 0.0726\n",
            "Epoch 351/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5347 - val_loss: 0.2162\n",
            "Epoch 352/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9466 - val_loss: 0.4369\n",
            "Epoch 353/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0833 - val_loss: 0.5091\n",
            "Epoch 354/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1415 - val_loss: 0.2505\n",
            "Epoch 355/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1878 - val_loss: 2.6480\n",
            "Epoch 356/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1102 - val_loss: 0.2177\n",
            "Epoch 357/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8250 - val_loss: 0.1139\n",
            "Epoch 358/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7603 - val_loss: 0.6140\n",
            "Epoch 359/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.8647 - val_loss: 0.0506\n",
            "Epoch 360/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.9238 - val_loss: 0.1944\n",
            "Epoch 361/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5571 - val_loss: 0.7950\n",
            "Epoch 362/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5147 - val_loss: 0.1596\n",
            "Epoch 363/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4170 - val_loss: 0.1122\n",
            "Epoch 364/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4226 - val_loss: 0.0876\n",
            "Epoch 365/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3990 - val_loss: 0.0768\n",
            "Epoch 366/400\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4203 - val_loss: 0.0206\n",
            "Epoch 367/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4245 - val_loss: 0.0720\n",
            "Epoch 368/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4006 - val_loss: 0.2189\n",
            "Epoch 369/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3348 - val_loss: 0.1361\n",
            "Epoch 370/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3322 - val_loss: 0.1258\n",
            "Epoch 371/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3548 - val_loss: 0.0624\n",
            "Epoch 372/400\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4084 - val_loss: 0.0622\n",
            "Epoch 373/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3397 - val_loss: 0.0394\n",
            "Epoch 374/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4552 - val_loss: 0.2170\n",
            "Epoch 375/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4984 - val_loss: 0.1517\n",
            "Epoch 376/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4719 - val_loss: 0.2997\n",
            "Epoch 377/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5012 - val_loss: 0.0972\n",
            "Epoch 378/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4638 - val_loss: 0.1110\n",
            "Epoch 379/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7764 - val_loss: 0.3858\n",
            "Epoch 380/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5161 - val_loss: 0.2317\n",
            "Epoch 381/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4986 - val_loss: 0.2420\n",
            "Epoch 382/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4065 - val_loss: 0.0969\n",
            "Epoch 383/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3390 - val_loss: 0.1658\n",
            "Epoch 384/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5502 - val_loss: 0.1702\n",
            "Epoch 385/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6535 - val_loss: 0.6461\n",
            "Epoch 386/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6141 - val_loss: 0.1216\n",
            "Epoch 387/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6725 - val_loss: 0.5400\n",
            "Epoch 388/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5298 - val_loss: 0.0968\n",
            "Epoch 389/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5009 - val_loss: 0.1025\n",
            "Epoch 390/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2985 - val_loss: 0.1217\n",
            "Epoch 391/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4435 - val_loss: 0.1905\n",
            "Epoch 392/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3287 - val_loss: 0.1058\n",
            "Epoch 393/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3193 - val_loss: 0.0605\n",
            "Epoch 394/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3135 - val_loss: 0.0983\n",
            "Epoch 395/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2977 - val_loss: 0.0310\n",
            "Epoch 396/400\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3780 - val_loss: 0.0465\n",
            "Epoch 397/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4144 - val_loss: 0.1126\n",
            "Epoch 398/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3615 - val_loss: 0.1956\n",
            "Epoch 399/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4191 - val_loss: 0.1425\n",
            "Epoch 400/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5649 - val_loss: 0.1189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llXIizO68-X_",
        "outputId": "9479c1af-9443-4416-a223-b5ca2db62d29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt #Para Gerar Plots\n",
        "\n",
        "plt.plot(history.history['loss'][0:500])\n",
        "plt.plot(history.history['val_loss'][0:500])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY2uVg90mQEo"
      },
      "source": [
        "## Avaliando a rede neural e comparando as saídas obtidas com as reais"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQpFed8vmQEp",
        "outputId": "f1bd3a5d-15a9-42f6-8713-5905c68a80e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred = model.predict(entradasTeste)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa57de16a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r1_cf6BmQEs",
        "outputId": "311b5ca0-0e4b-4cdd-84fe-db97c9fa1433",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('MAE:', mean_absolute_error(saidasTeste, y_pred))  \n",
        "print('MSE:', mean_squared_error(saidasTeste, y_pred))  \n",
        "print('RMSE:', np.sqrt(mean_squared_error(saidasTeste, y_pred)))\n",
        "print('R2_Score:', r2_score(saidasTeste, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: 0.11779944713299091\n",
            "MSE: 0.03221005936411267\n",
            "RMSE: 0.17947161158275887\n",
            "R2_Score: 0.9926834676982056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XTukCmzmQEu",
        "outputId": "b09f0033-6c6a-45ff-b14e-e920f6ebfd7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "fig = plt.figure(figsize=(10,5))\n",
        "plt.scatter(saidasTeste,y_pred)\n",
        "plt.plot(saidasTeste,saidasTeste,'r')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa57d3fc048>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}